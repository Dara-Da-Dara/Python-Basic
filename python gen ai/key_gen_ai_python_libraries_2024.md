# ðŸ”‘ Key Gen-AI Python Libraries / Frameworks with 2024 Activity

---

## 1. Hugging Face Transformers
**Description:** The de-facto Python library for loading and running pretrained LLMs and multimodal models. Hugging Face shipped multiple 2024 releases with ongoing enhancements to model support, pipeline features, and dtype/quantization options.  
**Why it mattered in 2024:** Continued model & pipeline improvements made it the central API for many Gen-AI projects.  

**Install:**
```bash
pip install transformers
```

---

## 2. Hugging Face Diffusers
**Description:** Modular diffusion model tooling (image, audio, video pipelines). Diffusers had notable 2024 releases adding new pipelines, training scripts, and quantization backends. Great for image/video generative workflows.  

**Install:**
```bash
pip install diffusers
```

---

## 3. LangChain (Python)
**Description:** The leading orchestration/framework for building LLM apps (chains, agents, tools, memory). LangChain continued major 2024 growth (product reports and ecosystem expansion) and remained a primary framework for app-level Gen-AI development.  

**Install:**
```bash
pip install langchain
```

---

## 4. bitsandbytes
**Description:** Low-level k-bit quantization and optimizers enabling memory-efficient inference/training. Wheel releases in early 2024 helped run large models on narrower GPU RAM. Widely used with Transformers/Diffusers for 4/8-bit workflows.  

**Install:**
```bash
pip install bitsandbytes
```

---

## 5. tiktoken
**Description:** OpenAIâ€™s fast BPE tokenizer library with several 2024 releases (used for token counting/encoding for modern models). Critical for cost/token accounting and model input prep.  

**Install:**
```bash
pip install tiktoken
```

---

## 6. PEFT (Hugging Face PEFT)
**Description:** Parameter-efficient fine-tuning utilities (LoRA, adapters, etc.). PEFT continued incremental releases through 2024 and remained the standard approach for efficient SFT/LoRA-style fine tuning.  

**Install:**
```bash
pip install peft
```

---

## 7. llama-cpp-python
**Description:** Python bindings for llama.cpp (local LLM inference). Actively updated in 2024 so that local/offline LLM usage in Python apps became far more practical. Good if you need local open-source LLM inference.  

**Install:**
```bash
pip install llama-cpp-python
```

---
